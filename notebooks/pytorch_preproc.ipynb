{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from nltk import WhitespaceTokenizer\n",
    "\n",
    "from src.NLP.nlp_base import NLPBaseDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find a way to convert the start/end indices of the character of each labelled text to the start/end indices of the tokens corresponding to the annotated words.\n",
    "\n",
    "E.g. \n",
    "\n",
    "Current setup: `sentence = 'This is an example'`\n",
    "               \n",
    "               label    = [{char_start: 8, char_end: 18, text: 'an example', label: 'EXAMPLE'}]\n",
    "                \n",
    "Desired setup: `sentence = ['This', 'is', 'an',      'example']`\n",
    "               \n",
    "               label    = ['O',    'O',  'EXAMPLE', 'EXAMPLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(0, 4), (5, 7), (8, 15), (16, 23), (24, 28), (29, 37), (38, 44)], ['This', 'is', 'another', 'example', 'with', 'multiple', 'annots'])\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    {'data': 'This is an example', 'label': [{'char_start': 8, 'char_end': 18, 'text': 'an example', 'label': 'EXAMPLE'}]},\n",
    "    {'data': 'This is another example', 'label': [{'char_start': 8, 'char_end': 15, 'text': 'another', 'label': 'STH'}]},\n",
    "    {\n",
    "        'data': 'This is another example with multiple annots', 'label': [\n",
    "            {'char_start': 8, 'char_end': 15, 'text': 'another', 'label': 'STH'},\n",
    "            {'char_start': 16, 'char_end': 23, 'text': 'example', 'label': 'EXAMPLE'},\n",
    "            {'char_start': 38, 'char_end': 44, 'text': 'a third', 'label': 'ANNOT'}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "sample = samples[2]\n",
    "\n",
    "def span_tokenize(text):\n",
    "    # basic space-based tokenizer\n",
    "    # TODO: Also consider using huggingface tok\n",
    "    # https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
    "    spans = [token for token in WhitespaceTokenizer().span_tokenize(text)]\n",
    "    tokenized_text = [text[span[0]: span[1]] for span in spans]\n",
    "    return spans, tokenized_text\n",
    "\n",
    "print(span_tokenize(sample['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(entry: dict):\n",
    "    spans, tokenized_text = span_tokenize(entry['data'])\n",
    "    new_labels = ['O']*len(tokenized_text)\n",
    "    for annot in entry['label']:\n",
    "        label_start = annot['char_start']\n",
    "        label_end = annot['char_end']\n",
    "        for i, span in enumerate(spans):\n",
    "            start, end = span\n",
    "            label = 'O'\n",
    "            if (label_start <= start <= label_end) and (label_start <= end <= label_end):\n",
    "                label = annot['label']\n",
    "                assert new_labels[i] == \"O\", f\"{new_labels=} {i=} {span=} {label=}, {annot=}\"\n",
    "                new_labels[i] = label\n",
    "    new_entry = {\n",
    "        \"data\": tokenized_text,\n",
    "        \"label\": new_labels\n",
    "    }\n",
    "    return new_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': ['This', 'is', 'another', 'example', 'with', 'multiple', 'annots'],\n",
       " 'label': ['O', 'O', 'STH', 'EXAMPLE', 'O', 'O', 'ANNOT']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-GIJ9yZz_-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d05cb7d951b8036ae68f3a280aed36c3e6d36951248d87ebe17c17bdf4a6f2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
